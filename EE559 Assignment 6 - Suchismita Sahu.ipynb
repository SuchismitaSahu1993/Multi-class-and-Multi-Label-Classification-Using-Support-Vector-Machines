{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EE559 Assignment 6 : Classification using SVM, Anuran Calls Dataset\n",
    "\n",
    "### @author : Suchismita Sahu, USCID : 7688176370"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download the Anuran Calls (MFCCs) Data Set from: https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs). Choose 70% of the data randomly as the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Information:\n",
    "\n",
    "This dataset was used in several classifications tasks related to the challenge of anuran species recognition through their calls. It is a multilabel dataset with three columns of labels. These coefficients were normalized between -1 mfcc 1. The amount of instances per class are: \n",
    "\n",
    "Families: \n",
    "Bufonidae 68 \n",
    "Dendrobatidae 542 \n",
    "Hylidae 2165 \n",
    "Leptodactylidae 4420 \n",
    "\n",
    "Genus: \n",
    "Adenomera 4150 \n",
    "Ameerega 542 \n",
    "Dendropsophus 310 \n",
    "Hypsiboas 1593 \n",
    "Leptodactylus 270 \n",
    "Osteocephalus 114 \n",
    "Rhinella 68 \n",
    "Scinax 148 \n",
    "\n",
    "Species: \n",
    "AdenomeraAndre 672 \n",
    "AdenomeraHylaedactâ€¦ 3478 \n",
    "Ameeregatrivittata 542 \n",
    "HylaMinuta 310 \n",
    "HypsiboasCinerascens 472 \n",
    "HypsiboasCordobae 1121 \n",
    "LeptodactylusFuscus 270 \n",
    "OsteocephalusOophaâ€¦ 114 \n",
    "Rhinellagranulosa 68 \n",
    "ScinaxRuber 148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    "import math\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "data = pd.read_csv(r\"C:\\Users\\AbsurdFantasy\\Documents\\EE559 Assignments\\Assignment 3\\Anuran Calls (MFCCs)\\Frogs_MFCCs.csv\")  \n",
    "\n",
    "#Exploratory Data Analysis\n",
    "#data.shape\n",
    "#data.head() \n",
    "\n",
    "# Spliting Data and Labels\n",
    "\n",
    "X = data.drop(['Family', 'Genus', 'Species', 'RecordID'], axis=1)\n",
    "Yfamily= pd.DataFrame(data['Family'])\n",
    "Ygenus = pd.DataFrame(data['Genus'])\n",
    "Yspecies = pd.DataFrame(data['Species'])\n",
    "#X.shape\n",
    "#Yfamily.shape\n",
    "\n",
    "#Encoding the labels as int\n",
    "\n",
    "Yfamily[\"Family\"] = Yfamily[\"Family\"].astype('category')\n",
    "Yfamily.dtypes\n",
    "Yfamily[\"Label\"] = Yfamily[\"Family\"].cat.codes\n",
    "\n",
    "Ygenus[\"Genus\"] = Ygenus[\"Genus\"].astype('category')\n",
    "Ygenus.dtypes\n",
    "Ygenus[\"Label\"] = Ygenus[\"Genus\"].cat.codes\n",
    "\n",
    "Yspecies[\"Species\"] = Yspecies[\"Species\"].astype('category')\n",
    "Yspecies.dtypes\n",
    "Yspecies[\"Label\"] = Yspecies[\"Species\"].cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Each instance has three labels: Families, Genus, and Species. Each of the labels has multiple classes. We wish to solve a multi-class and multi-label problem. One of the most important approaches to multi-class classification is to train a classifier for each label. We first try this approach:\n",
    "\n",
    "### i. Research exact match and hamming score/ loss methods for evaluating multi-label classification and use them in evaluating the classifiers in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation.1 You are welcome to try to solve the problem with both normalized and raw attributes and report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Defined for Parameter Grid Search using CV to get best SVM Penalty and Width of Gaussian Kernel\n",
    "\n",
    "def svc_param_selection(X, y):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "    gammas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=10)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM Penalty for Gaussian Kernel and One-vs All for Family Label is: 10\n",
      "The best width of Gaussian Kernel for Family Label is: 1.9\n",
      "The Accuracy for Gaussian Kernel One-vs-All SVM for Family Label is: 0.9925891616489115\n",
      "The Hamming Loss is: 0.00741084\n"
     ]
    }
   ],
   "source": [
    "# SVM with Gaussian Kernel and One-vs-All Classification For Label Family\n",
    "\n",
    "X_train, X_test, Yfamily_train, Yfamily_test = train_test_split(X, Yfamily['Family'], test_size = 0.30)\n",
    "\n",
    "best_params = svc_param_selection(X_train, Yfamily_train)\n",
    "print('The best SVM Penalty for Gaussian Kernel and One-vs All for Family Label is:', best_params['C'])\n",
    "print('The best width of Gaussian Kernel for Family Label is:', best_params['gamma'])\n",
    "svclassifier = SVC(kernel='rbf', C = best_params['C'], gamma = best_params['gamma'])  \n",
    "\n",
    "svclassifier.fit(X_train, Yfamily_train) \n",
    "Yfamily_predsvm = svclassifier.predict(X_test)\n",
    "\n",
    "Accuracy = svclassifier.score(X_test, Yfamily_test)\n",
    "print('The Accuracy for Gaussian Kernel One-vs-All SVM for Family Label is:', Accuracy)\n",
    "\n",
    "hammingGaussianFam = []\n",
    "hammingGaussianFam = hamming_loss(Yfamily_test, Yfamily_predsvm)\n",
    "\n",
    "print('The Hamming Loss is: %.8f' %hamming_loss(Yfamily_test, Yfamily_predsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM Penalty for Gaussian Kernel and One-vs All for Genus Label is: 10\n",
      "The best width of Gaussian Kernel for Genus Label is: 2\n",
      "The Accuracy Gaussian Kernel One-vs-All SVM for Family Label is: 0.9916628068550255\n",
      "The Hamming Loss is: 0.00833719\n"
     ]
    }
   ],
   "source": [
    "# SVM with Gaussian Kernel and One-vs-All Classification For Label Genus\n",
    "\n",
    "X_train, X_test, Ygenus_train, Ygenus_test = train_test_split(X, Ygenus['Genus'], test_size = 0.30)\n",
    "\n",
    "best_params = svc_param_selection(X_train, Ygenus_train)\n",
    "print('The best SVM Penalty for Gaussian Kernel and One-vs All for Genus Label is:', best_params['C'])\n",
    "print('The best width of Gaussian Kernel for Genus Label is:', best_params['gamma'])\n",
    "svclassifier = SVC(kernel='rbf', C = best_params['C'], gamma = best_params['gamma'])  \n",
    "\n",
    "svclassifier.fit(X_train, Ygenus_train) \n",
    "Ygenus_predsvm = svclassifier.predict(X_test) \n",
    "\n",
    "Accuracy = svclassifier.score(X_test, Ygenus_test)\n",
    "print('The Accuracy Gaussian Kernel One-vs-All SVM for Family Label is:', Accuracy)\n",
    "\n",
    "hammingGaussianGen = []\n",
    "hammingGaussianGen = hamming_loss(Ygenus_test, Ygenus_predsvm)\n",
    "\n",
    "print('The Hamming Loss is: %.8f' %hamming_loss(Ygenus_test, Ygenus_predsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM Penalty for Gaussian Kernel and One-vs All for Species Label is: 10\n",
      "The best width of Gaussian Kernel for Species Label is: 1.9\n",
      "The Accuracy Gaussian Kernel One-vs-All SVM for Species Label is: 0.9874942102825383\n",
      "The Hamming Loss is: 0.01250579\n"
     ]
    }
   ],
   "source": [
    "# SVM with Gaussian Kernel and One-vs-All Classification For Label Species\n",
    "\n",
    "X_train, X_test, Yspecies_train, Yspecies_test = train_test_split(X, Yspecies['Species'], test_size = 0.30)\n",
    "\n",
    "best_params = svc_param_selection(X_train, Yspecies_train)\n",
    "print('The best SVM Penalty for Gaussian Kernel and One-vs All for Species Label is:', best_params['C'])\n",
    "print('The best width of Gaussian Kernel for Species Label is:', best_params['gamma'])\n",
    "svclassifier = SVC(kernel='rbf', C = best_params['C'], gamma = best_params['gamma'])  \n",
    "\n",
    "svclassifier.fit(X_train, Yspecies_train) \n",
    "Yspecies_predsvm = svclassifier.predict(X_test)\n",
    "\n",
    "Accuracy = svclassifier.score(X_test, Yspecies_test) \n",
    "print('The Accuracy Gaussian Kernel One-vs-All SVM for Species Label is:', Accuracy)\n",
    "\n",
    "hammingGaussianSp = []\n",
    "hammingGaussianSp = hamming_loss(Yspecies_test, Yspecies_predsvm)\n",
    "\n",
    "print('The Hamming Loss is: %.8f' %hamming_loss(Yspecies_test, Yspecies_predsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenaing the Test and Predicted outputs\n",
    "Ypredsvc = np.column_stack((Yfamily_predsvm, Ygenus_predsvm, Yspecies_predsvm))\n",
    "Ytestsvc = np.column_stack((Yfamily_test, Ygenus_test, Yspecies_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Finding Exact Match Score:\n",
    "\n",
    "def ExactMatchscore(Ypred, Ytrue):\n",
    "    score = 0\n",
    "    for i in range(Ypred.shape[0]):\n",
    "        if False not in (Ypred[i,:]==np.array((Ytrue))[i,:]):\n",
    "            score+=1\n",
    "            \n",
    "    return float(score/Ypred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Exact Match Score for SVM Classifier with Gaussian Kernel and One-vs-all is: 0.9726725335803613\n"
     ]
    }
   ],
   "source": [
    "ExactMatchScore = ExactMatchscore(Ypredsvc, Ytestsvc)\n",
    "print('The Exact Match Score for SVM Classifier with Gaussian Kernel and One-vs-all is:', ExactMatchScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating Hamming Loss for the Multiclass-Multilabel Problem\n",
    "\n",
    "def HammingLoss(Ypred, Ytrue):\n",
    "    score = 0\n",
    "    for i in range(Ypred.shape[0]):\n",
    "        for j in range(0,3):\n",
    "            if False == (Ypred[i,j]==Ytrue[i,j]):\n",
    "                score+=1\n",
    "            \n",
    "    return float(score/Ypred.shape[0]*3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hamming Loss for SVM Classifier with Gaussian Kernel and One-vs-all is: 0.08476146364057434\n"
     ]
    }
   ],
   "source": [
    "# Hamming Loss for the Multiclass-Multilabel Problem in Gaussian SVM\n",
    "\n",
    "#Hamming = ((hammingGaussianFam + hammingGaussianGen + hammingGaussianSp)/3)\n",
    "#print('The Hamming Loss for the Gaussian One vs. All SVM is:', Hamming)\n",
    "\n",
    "Hamming_Loss_SVC = HammingLoss(Ypredsvc, Ytestsvc)\n",
    "print('The Hamming Loss for SVM Classifier with Gaussian Kernel and One-vs-all is:', Hamming_Loss_SVC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Repeat 1(b)ii with L1-penalized SVMs. Remember to normalize the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Function to find Best weight of SVM Penalty for L1-Penalized SVM \n",
    "\n",
    "def linearsvc_param_selection(X, y):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "    param_grid = {'C': Cs}\n",
    "    grid_search = GridSearchCV(svm.LinearSVC(penalty = 'l1', dual = False), param_grid, cv=10)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Penalty for L1-Penalized SVM for Family Label is: 10\n",
      "The Accuracy for L1-Penalized SVM for Family Label is: 0.9305233904585456\n",
      "The Hamming Loss is: 0.06947661\n"
     ]
    }
   ],
   "source": [
    "# L1-Penalized SVM for Family Label\n",
    "\n",
    "X_train, X_test, Yfamily_train, Yfamily_test = train_test_split(X, Yfamily['Family'], test_size = 0.30)\n",
    "\n",
    "best_params2 = linearsvc_param_selection(X_train, Yfamily_train)\n",
    "print('The best Penalty for L1-Penalized SVM for Family Label is:', best_params2['C'])\n",
    "\n",
    "svmpenalized = LinearSVC(penalty='l1', C = best_params2['C'], dual = False)  \n",
    "svmpenalized.fit(X_train, Yfamily_train) \n",
    "Yfamily_predl1 = svmpenalized.predict(X_test)\n",
    "\n",
    "Accuracy = svmpenalized.score(X_test, Yfamily_test) \n",
    "print('The Accuracy for L1-Penalized SVM for Family Label is:', Accuracy)\n",
    "\n",
    "hammingGaussianFam1 = []\n",
    "hammingGaussianFam1 = hamming_loss(Yfamily_test, Yfamily_predl1)\n",
    "\n",
    "print('The Hamming Loss is: %.8f' %hamming_loss(Yfamily_test, Yfamily_predl1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Penalty for L1-Penalized SVM for Genus Label is: 100\n",
      "The Accuracy for L1-Penalized SVM for Genus Label is: 0.9481241315423807\n",
      "The Hamming Loss is: 0.05187587\n"
     ]
    }
   ],
   "source": [
    "# L1-Penalized SVM for Genus Label\n",
    "\n",
    "X_train, X_test, Ygenus_train, Ygenus_test = train_test_split(X, Ygenus['Genus'], test_size = 0.30)\n",
    "\n",
    "best_params2 = linearsvc_param_selection(X_train, Ygenus_train)\n",
    "print('The best Penalty for L1-Penalized SVM for Genus Label is:', best_params2['C'])\n",
    "\n",
    "svmpenalized = LinearSVC(penalty='l1', C = best_params2['C'], dual = False)  \n",
    "svmpenalized.fit(X_train, Ygenus_train) \n",
    "Ygenus_predl1 = svmpenalized.predict(X_test)\n",
    "\n",
    "Accuracy = svmpenalized.score(X_test, Ygenus_test)  \n",
    "print('The Accuracy for L1-Penalized SVM for Genus Label is:', Accuracy)\n",
    "\n",
    "hammingGaussianGen1 = []\n",
    "hammingGaussianGen1 = hamming_loss(Ygenus_test, Ygenus_predl1)\n",
    "\n",
    "print('The Hamming Loss is: %.8f' %hamming_loss(Ygenus_test, Ygenus_predl1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The The best Penalty for L1-Penalized SVM for Species Label is: 10\n",
      "The Accuracy for L1-Penalized SVM for Species Label is: 0.952292728114868\n",
      "The Hamming Loss is: 0.04770727\n"
     ]
    }
   ],
   "source": [
    "# L1-Penalized SVM for Species Label\n",
    "\n",
    "X_train, X_test, Yspecies_train, Yspecies_test = train_test_split(X, Yspecies['Species'], test_size = 0.30)\n",
    "\n",
    "best_params2 = linearsvc_param_selection(X_train, Yspecies_train)\n",
    "print('The The best Penalty for L1-Penalized SVM for Species Label is:', best_params2['C'])\n",
    "\n",
    "svmpenalized = LinearSVC(penalty='l1', C = best_params2['C'], dual = False)  \n",
    "svmpenalized.fit(X_train, Yspecies_train) \n",
    "Yspecies_predl1 = svmpenalized.predict(X_test)\n",
    "\n",
    "Accuracy = svmpenalized.score(X_test, Yspecies_test)  \n",
    "print('The Accuracy for L1-Penalized SVM for Species Label is:', Accuracy)\n",
    "\n",
    "hammingGaussianSp1 = []\n",
    "hammingGaussianSp1 = hamming_loss(Yspecies_test, Yspecies_predl1)\n",
    "\n",
    "print('The Hamming Loss is: %.8f' %hamming_loss(Yspecies_test, Yspecies_predl1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenaing the Test and Predicted outputs\n",
    "\n",
    "Ypredl1 = np.column_stack((Yfamily_predl1, Ygenus_predl1, Yspecies_predl1))\n",
    "Ytestl1 = np.column_stack((Yfamily_test, Ygenus_test, Yspecies_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Exact Match Score for L1-Penalized SVM Classifier is: 0.8388142658638258\n"
     ]
    }
   ],
   "source": [
    "#Exact Match Score for L1-Penalized SVM\n",
    "\n",
    "ExactMatchScore1 = ExactMatchscore(Ypredl1, Ytestl1)\n",
    "print('The Exact Match Score for L1-Penalized SVM Classifier is:', ExactMatchScore1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Hamming Loss for L1-Penalized SVM Classifier is: 0.056353249961401876\n",
      "The Hamming Loss for L1-Penalized SVM Classifier Combined is: 0.507179249652617\n"
     ]
    }
   ],
   "source": [
    "# Hamming Loss for the Multiclass-Multilabel Problem using L1-Penalized SVM \n",
    "\n",
    "Hamming2 = ((hammingGaussianFam1 + hammingGaussianGen1 + hammingGaussianSp1)/3)\n",
    "#print('The Hamming Loss for L1-Penalized SVM is:', Hamming2)\n",
    "\n",
    "Hamming_Loss_L1 = HammingLoss(Ypredl1, Ytestl1)\n",
    "print('The Mean Hamming Loss for L1-Penalized SVM Classifier is:', Hamming2)\n",
    "print('The Hamming Loss for L1-Penalized SVM Classifier Combined is:', Hamming_Loss_L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance. Report your conclusions about the classifiers you trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM Penalty for L1-Penalized SVM using SMOTE for Family Label is: 10000\n",
      "The Accuracy for L1-Penalized SVM using SMOTE for Family Label is: 0.9036591014358499\n",
      "The Hamming Loss is: 0.09634090\n"
     ]
    }
   ],
   "source": [
    "# L1-Penalized SVM using SMOTE for Label Family\n",
    "\n",
    "X_train, X_test, Yfamily_train, Yfamily_test = train_test_split(X, Yfamily['Family'], test_size = 0.3)\n",
    "\n",
    "sm = SMOTE(kind = 'svm')\n",
    "X_train_res, Yfamily_train_res = sm.fit_sample(X_train, Yfamily_train)\n",
    "\n",
    "best_params3 = linearsvc_param_selection(X_train_res, Yfamily_train_res)\n",
    "print('The best SVM Penalty for L1-Penalized SVM using SMOTE for Family Label is:', best_params3['C']) \n",
    "\n",
    "svmpenalized = LinearSVC(penalty='l1', C = best_params3['C'], dual = False)\n",
    "svmpenalized.fit(X_train_res, Yfamily_train_res)\n",
    "Yfamily_predsmote = svmpenalized.predict(X_test)\n",
    "\n",
    "Accuracy = svmpenalized.score(X_test, Yfamily_test) \n",
    "print('The Accuracy for L1-Penalized SVM using SMOTE for Family Label is:', Accuracy)\n",
    "\n",
    "hammingGaussianFam2 = []\n",
    "hammingGaussianFam2 = hamming_loss(Yfamily_test, Yfamily_predsmote)\n",
    "\n",
    "print('The Hamming Loss is: %.8f' %hamming_loss(Yfamily_test, Yfamily_predsmote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM Penalty for L1-Penalized SVM using SMOTE for Genus Label is: 100\n",
      "The Accuracy for L1-Penalized SVM using SMOTE for Genus Label is: 0.8818897637795275\n",
      "The Hamming Loss is: 0.11811024\n"
     ]
    }
   ],
   "source": [
    "# L1-Penalized SVM using SMOTE for Label Genus\n",
    "\n",
    "X_train, X_test, Ygenus_train, Ygenus_test = train_test_split(X, Ygenus['Genus'], test_size = 0.3)\n",
    "\n",
    "sm = SMOTE(kind = 'svm')\n",
    "X_train_res, Ygenus_train_res = sm.fit_sample(X_train, Ygenus_train)\n",
    "\n",
    "best_params3 = linearsvc_param_selection(X_train_res, Ygenus_train_res)\n",
    "print('The best SVM Penalty for L1-Penalized SVM using SMOTE for Genus Label is:', best_params3['C']) \n",
    "\n",
    "svmpenalized = LinearSVC(penalty='l1', C = best_params3['C'], dual = False)\n",
    "svmpenalized.fit(X_train_res, Ygenus_train_res)\n",
    "Ygenus_predsmote = svmpenalized.predict(X_test)\n",
    "\n",
    "Accuracy = svmpenalized.score(X_test, Ygenus_test) \n",
    "print('The Accuracy for L1-Penalized SVM using SMOTE for Genus Label is:', Accuracy)\n",
    "\n",
    "hammingGaussianGen2 = []\n",
    "hammingGaussianGen2 = hamming_loss(Ygenus_test, Ygenus_predsmote)\n",
    "\n",
    "print('The Hamming Loss is: %.8f' %hamming_loss(Ygenus_test, Ygenus_predsmote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best SVM Penalty for L1-Penalized SVM using SMOTE for Species Label is: 100\n",
      "The Accuracy for L1-Penalized SVM using SMOTE for Species Label is: 0.9124594719777674\n",
      "The Hamming Loss is: 0.08754053\n"
     ]
    }
   ],
   "source": [
    "# L1-Penalized SVM using SMOTE for Label Species\n",
    "\n",
    "X_train, X_test, Yspecies_train, Yspecies_test = train_test_split(X, Yspecies['Species'], test_size = 0.3)\n",
    "\n",
    "sm = SMOTE(kind = 'svm')\n",
    "X_train_res, Yspecies_train_res = sm.fit_sample(X_train, Yspecies_train)\n",
    "\n",
    "best_params3 = linearsvc_param_selection(X_train_res, Yspecies_train_res)\n",
    "print('The best SVM Penalty for L1-Penalized SVM using SMOTE for Species Label is:', best_params3['C']) \n",
    "\n",
    "svmpenalized = LinearSVC(penalty='l1', C = best_params3['C'], dual = False)\n",
    "svmpenalized.fit(X_train_res, Yspecies_train_res)\n",
    "Yspecies_predsmote = svmpenalized.predict(X_test)\n",
    "\n",
    "Accuracy = svmpenalized.score(X_test, Yspecies_test) \n",
    "print('The Accuracy for L1-Penalized SVM using SMOTE for Species Label is:', Accuracy)\n",
    "\n",
    "hammingGaussianSp2 = []\n",
    "hammingGaussianSp2 = hamming_loss(Yspecies_test, Yspecies_predsmote)\n",
    "\n",
    "print('The Hamming Loss is: %.8f' %hamming_loss(Yspecies_test, Yspecies_predsmote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Exact Match Score for L1-Penalized SVM Classifier using SMOTE is: 0.7285780453913849\n",
      "The Mean Hamming Loss for L1-Penalized SVM using SMOTE is: 0.10066388760228501\n",
      "The Hamming Loss for L1-Penalized SVM using SMOTE is: 0.905974988420565\n"
     ]
    }
   ],
   "source": [
    "# Hamming Loss for the Multiclass-Multilabel Problem using L1-Penalized SVM using SMOTE\n",
    "\n",
    "Hamming3 = ((hammingGaussianFam2 + hammingGaussianGen2 + hammingGaussianSp2)/3)\n",
    "#print('The Hamming Loss for L1-Penalized SVM using SMOTE is:', Hamming3) \n",
    "\n",
    "Ypredsmote = np.column_stack((Yfamily_predsmote, Ygenus_predsmote, Yspecies_predsmote))\n",
    "Ytestsmote = np.column_stack((Yfamily_test, Ygenus_test, Yspecies_test))\n",
    "\n",
    "ExactMatchScore2 = ExactMatchscore(Ypredsmote, Ytestsmote )\n",
    "print('The Exact Match Score for L1-Penalized SVM Classifier using SMOTE is:', ExactMatchScore2)\n",
    "\n",
    "Hamming_Loss_smote = HammingLoss(Ypredsmote, Ytestsmote)\n",
    "print('The Mean Hamming Loss for L1-Penalized SVM using SMOTE is:', Hamming3)\n",
    "print('The Hamming Loss for L1-Penalized SVM using SMOTE is:', Hamming_Loss_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "## For Family Label\n",
    "\n",
    "### SVM classifier with Gaussian Kernel and One-vs All :\n",
    "##### The best SVM Penalty is: \n",
    "10 \n",
    "##### The best width of Gaussian Kernel is : \n",
    "1.9\n",
    "##### The Accuracy is: \n",
    "0.9925891616489115\n",
    "##### The Hamming Loss is: \n",
    "0.00741084\n",
    "\n",
    "### L1-Penalized SVM classifier :\n",
    "##### The best Penalty is: \n",
    "10\n",
    "##### The Accuracy is: \n",
    "0.9302501157943493\n",
    "##### The Hamming Loss is: \n",
    "0.069497661\n",
    "\n",
    "### L1-Penalized SVM classifier using SMOTE :\n",
    "##### The best SVM Penalty is: \n",
    "10000\n",
    "##### The Accuracy is: \n",
    "0.90365910143584\n",
    "##### The Hamming Loss is: \n",
    "0.09634090\n",
    "\n",
    "## For Genus Label\n",
    "\n",
    "### SVM classifier with Gaussian Kernel and One-vs All :\n",
    "##### The best SVM Penalty is: \n",
    "10\n",
    "##### The best width of Gaussian Kernel is: \n",
    "2\n",
    "##### The Accuracy is: \n",
    "0.9916628068550255\n",
    "##### The Hamming Loss is: \n",
    "0.00833719\n",
    "\n",
    "### L1-Penalized SVM classifier :\n",
    "##### The best Penalty is: \n",
    "100\n",
    "##### The Accuracy is: \n",
    "0.9481241315423\n",
    "##### The Hamming Loss is: \n",
    "0.05187587\n",
    "\n",
    "### L1-Penalized SVM classifier using SMOTE :\n",
    "##### The best SVM Penalty is : \n",
    "100\n",
    "##### The Accuracy is : \n",
    "0.8809634089856415\n",
    "##### The Hamming Loss is: \n",
    "0.11811024\n",
    "\n",
    "\n",
    "## For Species Label\n",
    "\n",
    "### SVM classifier with Gaussian Kernel and One-vs All :\n",
    "##### The best SVM Penalty is: \n",
    "10\n",
    "##### The best width of Gaussian Kernel is: \n",
    "1.9\n",
    "##### The Accuracy is: \n",
    "0.9874942102825383\n",
    "##### The Hamming Loss is: \n",
    "0.01250579\n",
    "\n",
    "### L1-Penalized SVM classifier :\n",
    "##### The The best Penalty is: \n",
    "10\n",
    "##### The Accuracy is: \n",
    "0.960629921259842\n",
    "##### The Hamming Loss is: \n",
    "0.04770727\n",
    "\n",
    "### L1-Penalized SVM classifier using SMOTE :\n",
    "##### The best SVM Penalty is: \n",
    "100\n",
    "##### The Accuracy is: \n",
    "0.9128392774432608\n",
    "##### The Hamming Loss is: \n",
    "0.08754053\n",
    "\n",
    "### Exact Match Scores for the Combined Multiclass and Multilabel Classifier :\n",
    "#### SVM classifier with Gaussian Kernel and One-vs All : \n",
    "0.972672533580\n",
    "#### L1-Penalized SVM classifier : \n",
    "0.948124131542\n",
    "#### L1-Penalized SVM classifier using SMOTE :\n",
    "0.7285780453913\n",
    "\n",
    "\n",
    "\n",
    "### Hamming Loss for the Combined Multiclass and Multilabel Classifier :\n",
    "#### SVM classifier with Gaussian Kernel and One-vs All : \n",
    "0.084761463640\n",
    "#### L1-Penalized SVM classifier : \n",
    "0.50717924965\n",
    "#### L1-Penalized SVM classifier using SMOTE : \n",
    "0.9059749884205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v. Extra Practice: Study the Classifier Chain method and apply it to the aboveproblem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Chain Method for Multiclass-Multilabel Problem.\n",
    "\n",
    "X_train, X_test, Yfamily_train, Yfamily_test = train_test_split(X, Yfamily['Label'], test_size = 0.3)\n",
    "X_train, X_test, Ygenus_train, Ygenus_test = train_test_split(X, Ygenus['Label'], test_size = 0.3)\n",
    "X_train, X_test, Yspecies_train, Yspecies_test = train_test_split(X, Yspecies['Label'], test_size = 0.3)\n",
    "\n",
    "y_test = np.column_stack((Yfamily_test, Ygenus_test, Yspecies_test))\n",
    "y_train = np.column_stack((Yfamily_train, Ygenus_train, Yspecies_train))\n",
    "\n",
    "classifier = ClassifierChain(svm.SVC(C=100))\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
